@# ========================================================================== #@
@# QDS HELP ARTICLES                                                          #@
@# This file is processed by QDS Help tool.                                   #@
@# ========================================================================== #@
@#                                                                            #@
@#   Special tags (markers) used in this file:                                #@
@#                                                                            #@
@#       Markers used at line start:                                          #@
@#                                                                            #@
@#   @article                  - starts new article                           #@
@#   @todo                     - todo (highlighted by IDEA since version 7)   #@
@#                               and not processed by Help tool)              #@
@#   @#                        - line comment                                 #@
@#   @list-tools               - insert list of all QDS tools                 #@
@#   @list-connectors          - insert list of all MessageConnectors         #@
@#   @list-specific-filters    - insert list of project-specific filters      #@
@#   @tool-summary             - insert autogenerated tool usage info         #@
@#   @messageconnector-summary - insert autogenerated MessageConnector        #@
@#                               information summary                          #@
@#                                                                            #@
@#       Markers used in text:                                                #@
@#                                                                            #@
@#   @link{...}                - insert link to another article               #@
@#   @br;                      - insert line break                            #@
@#   @at;                      - replaced by '@'                              #@
@#                                                                            #@
@# ========================================================================== #@
@#
@#
@# ====== SPECIAL ARTICLES =====================================================
@article Tools
Available tools are:
@list-tools
@br;To get detailed help on some tool use "Help <tool name>".
@br;To get information about executing several tools under one JVM see @link{Batch}.
@# -----------------------------------------------------------------------------
@article Connectors
Available MessageConnectors are:
@list-connectors
To get detailed help on some MessageConnector use "Help <connector name>".
@br;See also: @link{Address}.
@# ====== ARTICLES ABOUT QDS TOOLS =============================================
@article Help
@tool-summary
@br;To see help on some topic type "Help <topic>".
@br;To see list of all articles type "Help contents".
@br;Use "Help all" to generate all existing help articles.
@# -----------------------------------------------------------------------------
@article Connect
@tool-summary

This tool is used to connect to some address with specified subscription, and
log or tape received data. By default it just logs all received records to
a screen in text format (see @link{text format}).

There are two ways to define the subscription for this tool. One can either
define comma separated lists of records and symbols to subscribe for (and
date-time for history subscription also) or define an address to copy
subscription from. For example in the second case it can be an uplink address
of the server which we are connecting to. This way we can subscribe to all records
and symbols which this server subscribes by itself.

Note, that when defining <records> parameter one can use more complicated
filters than just a list of record names (see @link{filters}), but each pattern
filter (not depending on whether it starts with ':' or not) is considered to be
a record filter.

The main extra-functionality of the connect tool is taping data into file, which
can be performed using --tape option. (see @link{tape} for its detailed description
and samples).

Examples:

	Connect somehost:7777 Trade*,Quote MSFT,IBM
@br;This will connect to somehost:7777, subscribe to all records which names
starts with "Trade" and to record Quote about symbols MSFT and IBM using
ticker collector (which is default) and log received records to a screen.

	Connect somehost:7777 Trade*,Quote MSFT,IBM -q -tape quotes.log[time=text]
@br;This will do the same as the previous one except that it won't log records
to a screen but will tape them into file quotes.log (in binary format).

	Connect file:quotes.log Quote IBM
@br;This will connect to file quotes.log (created in previous example) and log
only Quote records about IBM symbol.

	Connect somehost:7777 somehost:7778
@br;If 7778 port is an uplink port of server somehost (i.e. it tries to get
record data from every connection and sends its subscription), then this command
will subscribe for everything that this server receives.

	Connect somehost:7777 Trade.Day GOOG 20080101 -c history
@br;This is the example of using history subscription (all Trade.Day records
about GOOG since the beginning of the year 2008).

Note, that samples above suppose that the scheme is defined using JVM option
-Dscheme=<...>.
@# -----------------------------------------------------------------------------
@article Tape

The --tape (-t) option of tool connect (see @link{connect}) is used to tape
all incoming data into the specified file. Such files later can be read using
FileConnector (see @link{FileConnector}).

This option has several parameters:

"format" parameter defines format of stored data. Its value can be one of
"text" (see @link{Text format}), "binary" or "blob:<record>:<symbol>"
(binary format is used by default). Blob is a special format that is used for
compact store of a single-record, single-symbol data stream.

"saveas" parameter overrides the type of stored messages. Data messages
can be stored as "ticker_data", "stream_data", "history_data", or "raw_data".

"split" parameter can be used to create multiple files with timestamped
names. Its value is time period (see @link{time format}) determining how often
must new files be created. When this parameter is defined a special '~' marker
in file name must be used (it will be replaced with file timestamp).

"time" parameter defines whether to create ".time" files. These files store
information about when each piece of data was recorded and are used to read
data from file in a realtime mode (keeping original time delays). ".time" file
format is simple: it contains lines with records of kind "<timestamp>:<file-position>".
The "time" parameter can be set into one of "none", "long" or "text".
In the first case no ".time" files are created. Otherwise the value defines
whether to write timestamps in ".time" files in old-style format (single
long value in milliseconds) or in human-readable text format (see @link{time format}).
By default ".time" files with old-style timestamps are created only if the file
has ".data" extension.

Two special parameters "storagesize" and "storagetime" are used to drop
out-of-date taped files.

"storagetime" parameter value is a time-period (see @link{Time format}).
If this parameter is defined then all taped files which have timestamps less
than current time minus "storagetime" value are deleted.

"storagesize" parameter is a number followed by one-character suffix 'b'
(bytes), 'k' (kilobytes), 'm' (megabytes), 'g' (gigabytes). If the suffix
is omitted then value in bytes is supposed. If this parameter is defined then
the total size of all existing taped files (not counting corresponding ".time"
files) is kept at value not much greater than "storagesize" value (also by means
of deleting older files).

Both these parameters guarantee that at least specified amount
of data is always stored, i.e. they define low boundary of stored data size.
These two parameters can be useful if we are implementing data delay by taping
data on disk.

Note, that all files that match specified timestamped-file pattern
are searched to be deleted when using these parameters (i.e. even if these files
weren't actually taped by this execution of connect tool).

Examples:

	--tape quotes.log
@br;will tape data into file "quotes.log" in binary format.
No ".time" files will be created.

	--tape quotes.log[saveas=ticker_data]
@br;will tape data into file "quotes.log" with "ticker_data" messages regardless of the
orignal type of the incoming data messages.

	--tape log[time=long]
@br;will tape data into file "log" and timestamps into
file "log.time" as long values (old-style).

	--tape log_~.txt[format=text,split=2m,time=text]
@br;will tape data in text format. It will create files like
	log_20071114-154214+0030.txt
	log_20071114-154214+0030.time
	log_20071114-154400+0300.txt
	log_20071114-154400+0300.time
	log_20071114-154600+0300.txt
	log_20071114-154600+0300.time
    ...
@br;creating new pair of ".txt" and ".time" files every 2 minutes.

	--tape log_~.dat[split=2m,time=text,storagesize=100k,storagetime=30m]
@br;will act similar to a previous sample (except it will create ".dat" files and
store data in binary format). Moreover it will keep only files taped during last
30 minutes and total size of these files will be not much more than 100 kb.
@# -----------------------------------------------------------------------------
@article Compare
@tool-summary

This tool compares two data sources and provides comparison information (about
data delays, dropped data percentage, etc.) to a screen and to MARS system.
It's general usage format is quite similar to Connect tool format (see
@lik{Connect}).

An alternative data source to compare with is specified using --other-address,
--other-collector, and --other-record options which can be combined in arbitrary way.
At least one of these options must always be set. --stat option must always
be set as well.

--other-address option is used to set alternative address for second connection.

--other-collector option is used to set second connection collector type
different from the first one i.e. data gathered with different collectors can be
compared.

--other-record option is used to compare two different records. When it is
used the <records> parameter must consist only of one record. Both comparing
records must have equal number of both int and obj fields. If one wish to compare
two records with different fields but he is interested only in several specific
fields, he can combine this option and --fields option to handle only required
fields.

--alias option can be used to give some aliases to comparing sources. These aliases
are used to identify sources when logging a statistics to a screen or when passing
it into MARS system. The value of this option consists of two names (one name for each
data source) separated by slash ('/'). These names must not contain '=' and '.'
symbols (due to MARS nodes naming restrictions). In case this option is omitted data
sources are just called "1" and "2".

Every n seconds (where n is the value of --stat option) the tool logs two separate
statistics lines for each of two connections, starting with "(<alias1>)" and
"(<alias2>)" (just the same as Connect tool does), and one additional statistics
line of the following format:
	"=== Matched: <m> / Compare: Dropped <d1>% vs <d2>%; Delay <t1> ms vs <t2> ms
/ Unmatched buf: <u>"
@br;<m> shows the number of records matched in two sources, <d1> and <d2> show
percent of records that were received in one source and were dropped in the
other one, <t1> and <t2> show average delay of records in one source relative to
another, and <u> shows how much last records were received from one source
and stored in buffer in order to be possibly matched later.

Besides logging to a screen the Compare tool provides statistics into specified
MARS node. To use this feature one should define two additional JVM parameters
(using java -D option): "mars.node=<root-MARS-node>" and "mars.address=:<port>".
In this case there will be MARS subtree with all comparison statistics (similar
to one, that is logged to a screen) created inside the root node. Besides total
average statistics this subtree will contain separate statistics nodes for each
record and for each pair <record, symbol>. The whole subtree would have a
following format:
@br;
@br;<1>/<2>
@br;	|-<Record#1>
@br;	|   |-<SYMBOL#1>
@br;	|   |   |-delay_<1>     \
@br;	|   |   |-delay_<2>      |
@br;	|   |   |-dropped_<1>    |
@br;	|   |   |-dropped_<2>     > Statistics for pair
@br;	|   |   |-matched        | <Record#1, SYMBOL#1>
@br;	|   |   |-unmatched_<1>  |
@br;	|   |   |-unmatched_<2> /
@br;	|   |-<SYMBOL#2>
@br;	|   |   |- ...
@br;	|   |-...
@br;	|   |-<SYMBOL#M>
@br;	|   |   |- ...
@br;	|   |-delay_<1>      \
@br;	|   |-delay_<2>       |
@br;	|   |-dropped_<1>     |
@br;	|   |-dropped_<2>      > Statistics for
@br;	|   |-matched         | <Record#1>
@br;	|   |-unmatched_<1>   |
@br;	|   |-unmatched_<2>  /
@br;	|-<Record#2>
@br;	|   |- ...
@br;	|- ...
@br;	|-<Record#N>
@br;	|   |- ...
@br;	|-delay_<1>      \
@br;	|-delay_<2>       |
@br;	|-dropped_<1>     |
@br;	|-dropped_<2>      > Overall statistics
@br;	|-matched         |
@br;	|-unmatched_<1>   |
@br;	|-unmatched_<2>  /

Here:
@br;	- <1> and <2> are aliases for the first and the second data sources.
@br;	- delay_<i> is average data delay (in milliseconds) of the corresponding
data source.
@br;	- dropped_<i> is average percentage of dropped data in the source.
@br;	- matched is the number of matched records.
@br;	- unmatched_<i> is the number of records in the source left unmatched yet.

These statistics refers to last monitoring period only (as well the one that is
logged to a console). If some node values are undefined (e.g. if no records was
received during last monitoring period) they are presented as "N/A".

If some symbol names contain '.' or '=' characters (which is allowed) they will be
replaced by '_' and '-' characters correspondingly in the MARS tree.

If aliases are not set for the data sources then the root of a subtree will have a
name "compare" instead of "1/2" (or "compare1", "compare2", ... if several tools
run inside one JVM (see @link{Batch})).

Example:

	Compare somehost:7777 Trade MSFT,IBM -s 10 -A anotherhost:1234 -C stream
@br;This will compare Trade records about MSFT and IBM symbols received from
somehost:7777 with ticker subscription with same records received from
anotherhost:1234 with stream subscription, and generate statistics on these two
connections and on correspondence between them every 10 seconds.

Note, that the sample above supposes that the scheme is defined using JVM option
-Dscheme=<...>.
@# -----------------------------------------------------------------------------
@article Dump
@tool-summary

This tool dumps all received data records and subscription items to a console.
It can connect to any address including plain file. Note, that it doesn't
send any subscription by itself, so if one connects it to some collector directly
it wouldn't receive or dump any data.
@# -----------------------------------------------------------------------------
@article Feed
@tool-summary

This tool multiplexes two addresses. It is quite similar to Multiplexor tool
(see @link{Multiplexor}). Its main difference from multiplexor is the fact
that it uses wildcard stream subscription to its data providers (instead of
passing his clients' subscriptions each time). Thus, it always receives all data
and if some client subscribes for new record it would start receiving it
immediately even if the feed tool is working in delaying mode. On the other hand
it means that a lot of memory is consumed regardless of the number of client
connections and their subscriptions.

Also it doesn't support data dropping feature unlike multiplexor.
@# -----------------------------------------------------------------------------
@article Multiplexor
@tool-summary

This tool multiplexes two addresses. It can be used to merge data from
several sources and provide it to multiple clients. All data providers connect
to <distributor-address> and all clients connect to <agent-address>.

Multiplexor creates a collector inside to store intermediate data (for all
types of subscription by default). Then every time it receives a subscription from
a client it stores it and also passes it to all of its data providers (connected
to a <distributor-address>). Then after it starts receiving required data from
providers it passes it to the client which subscribed on it. Thus, multiplexor
receives and stores only data that its client connections are interested in
(unlike Feed tool (see @link{Feed})).

Multiplexor also gives opportunities to delay data by specified period and
to drop some percent of data (by defining --delay and --drop options).

Note, that delaying data for long periods causes some problems. First, it
would consume lots of memory. Second, after some client subscribed on some new
record (and no other client was subscribed on it yet) it would start receiving
this records only after delay period. Even despite the fact that subscription
is passed immediately earlier instances of this record wouldn't present in
multiplexor's collector and the first one would be received after the moment
of subscription and stored for delay period.

Multiplexor tool (as well as Feed tool) can periodically dump records stored
in its collector to a file in order to restart without long gap in data flow in
case it was used to delay data and was restarted. The name of a storage file to
use can be defined by --file option. When it is set this file is automatically
loaded at startup. This option also allows to define filter of critical records
that must be dumped to this file. --write option defines how often to update the
storage file and must be used with the previous one.
@# -----------------------------------------------------------------------------
@article Post
@tool-summary

This tool is used to post data from console to specific address. The data
is read in text format (see @link{text format}). Collector type headers
(==QD_TICKER_DATA, ==QD_STREAM_DATA, ==QD_HISTORY_DATA, ==QD_RAW_DATA) and
record descriptions (=<record> Symbol <fields>) are also supported, so one can
just redirect a data file in text format (for example, taped by connect tool
earlier) to an input of this tool, instead of typing records manually.
Default data format is QD_RAW_DATA.

Some additional commands besides common text format syntax are supported:
	?             - Shows commands usage summary.
	? *           - Lists all record names in data scheme.
	? <record>... - Lists fields for specified record(s).
	.             - Quits.
@# -----------------------------------------------------------------------------
@article SchemeDump
@tool-summary

This tool dumps descriptions of all records and their fields of
defined scheme to a console.
@# -----------------------------------------------------------------------------
@article Time
@tool-summary

This tool tracks time in various JVMs via periodic multicast in
local network and shows error if this JVM's time has drifted too far
away (> 3 sec) from median time in this local network.
@# -----------------------------------------------------------------------------
@article NetTest
@tool-summary

This tool is used to test network throughput. It is quite similar to
TestThroughput tool from qd.sample, but it provides larger functionality
in network testing and is integrated into Tools framework.

The NetTest tool can be run in one of two modes: producer-side and
consumer-side. In each mode it creates one or several collectors and
connects them to specified address via MessageConnector.

When using NetTest as producer-side special generator thread is created
for every collector and it feeds the collector with randomly-generated
'Quote' records (and collector then gives them outside via connector). When using
as consumer-side each collector receives records from connector.

In both cases the number of generated/received records is counted
and throughput in records per second is logged to a console.

By default one connection (entity) from each side is created,
but their number can be changed using --connections option. A separate
collector is created for each entity.

Each producing entity continuously generates random records with symbols from
preliminarily generated symbols list. Each consumer entity is subscribed to some
records. Total number of symbols is defined by --symbols option (100000 by default).
If the second part of --symbols option is omitted then each entity will
use all symbols from the list. Otherwise one can define average number of
symbols (randomly selected from global symbol list) interesting per one
entity, i.e. number of symbols produced by single producer entity or number
of symbols which was single consumer entity subscribed to (see examples below).

The frequency of dumping throughput to a screen can be set using --stat option
(every 10 seconds by default).

Examples:

To start producer side on some server 'samplehost' at port 5555 one can run:
	NetTest p :5555
@br;It will randomly generate records about 100000 random symbols.

Then one can run consumer side on some other machine:
	nettest c samplehost:5555 -C 100 -S 100000/100
@br;This will create 100 connections. Each of them will subscribe to 'Quote'
record about roughly 100 symbols of 100000 randomly generated. Now one can
track the number of records received by these connections per second.

Note, that it is possible to connect multiple producers and multiple consumers with
each other via multiplexor. To do this one can start multiplexor on some server
'samplehost' using scheme SampleScheme:
	Multiplexor com.devexperts.qd.sample.SampleScheme :5555 :6666 --collector ticker

Then it is possible to run consumers and producers:
	NetTest p samplehost:5555 -C 10 -S 10000/1000
    NetTest c samplehost:6666 -C 10 -S 10000/1000
@# -----------------------------------------------------------------------------
@article Instruments
@tool-summary

The --read option can be either a network address or a file name. If it contains
colon (':') character then it is treated as a network address in a form "host:port",
otherwise it is treated as a file name. This option can be specified several times
in order to read and concatenate several data sources. All sources are loaded in
the order they are listed and concatenated into single data set.

The tool can read several input formats and convert them into IPF format.
The tool analyses file name to decide what input format is used.
@br;If file name contains ".xml" then it is considered to be OCC FIXML file.
@br;If file name contains "mo.dat" then it is considered to be CME MO.dat file.
@br;Otherwise file is considered to be IPF format file.

The tool supports file compression formats "zip" and "gzip" both for reading and writing.
The tool analyses file name to decide what compression format is used.
@br;If file name ends with ".zip" then "zip" format will be used.
@br;If file name ends with ".gz" then "gzip" format will be used.
@br;Otherwise no compression will be used.

The --transform option can be either a direct transform program, an URL or a file name
pointing to one. The tool treats option as direct one if it contains semicolon
(';') character, otherwise option is treated as an URL or file name depending on format.
This option can be specified several times in order to apply several separate transforms.
All transforms are executed one after another in the order they are listed.

Examples:

	Instruments -r thinkorswimseries_2008-05-19.xml.zip -t occ.transform -c -w occ_2008-05-19.ipf.zip
@br;This will read zipped OCC FIXML file "thinkorswimseries_2008-05-19.xml.zip",
transform it according to "occ.transform" program, run data checks and
write zipped instruments to "occ_2008-05-19.ipf.zip" file.

	Instruments -r mo.dat.zip -t cme.transform -w cme_2008-05-19.ipf.zip
@br;This will read zipped CME MO.dat file "mo.dat.zip", transform it according to
"cme.transform" program and write zipped instruments to "cme_2008-05-19.ipf.zip" file.

	Instruments -r data.ipf.zip -t 'if (UNDERLYING != "SPX") delete();' -w SPX.ipf
@br;This will read zipped IPF file "data.ipf.zip", transform it according to
specified program (deleting all instruments except "SPX" options) and write
uncompressed instruments to "SPX.ipf" file.

	Instruments -r main.ipf.zip -r missed.ipf -t cusip.transform -t sic.transform -m -w complete.ipf
@br;This will read zipped IPF file "main.ipf.zip" and uncompressed IPF file "missed.ipf",
concatenate them into single list, transform it according to both specified programs
(first "cusip.transform" and then "sic.transform"), merge duplicate entries by symbol
and finally write uncompressed instruments to IPF file "complete.ipf".
@# -----------------------------------------------------------------------------
@article Batch

It is possible to run several tools under one JVM. In order to do this one
can pass multiple tools initialization srtings separated by '+' sign. Each
executing tool receives its own parameters and options, but there are several
common options, that can be set only once (and would be available in all tools).
Such options are: -s|--stats, -l|--log, -h|--html-management and
-r|--rmi-management.

For example, it is possible to implement data delaying by running something
like: "java -jar -Dscheme=<...> qds-tools.jar Connect somehost:7777 SomeRecord
ASYMBOL --quiet --tape buffer~.dat[split=10m,storagetime=1h] --log log.txt +
Feed file:sample~.dat[start=-20m] :1234". This command will start Connect and
Feed tools running inside one JVM. Connect tool will tape data into buffer~.dat
files (where '~' is a timestamp), and Feed tool will read these files with 20
minute delay and send data to port 1234. Note, that both tools would use
log.txt to log information and errors (despite the fact that --log option was
set only in the first tool).
@# ====== ARTICLES ABOUT MESSAGE CONNECTORS ====================================
@article File
@messageconnector-summary

File connector receives a URL of a file as an address and connects to it.
It supports the same file formats as --tape option of Connect tool
(see @link{tape}) and they are usually combined.

It can read and give out all the data presented in a file at once, or it
can also use ".time" files to reproduce original delays. By default it uses
these files if they present, but this can be disabled by setting
"ignoretime=true".

File connector also supports reading multiple timestamped files. If
filename contains special '~' marker, then it is replaced with a timestamp.
For example, address "file:records~.dat" means that we want to seek for
files like records20080320-154914+0030.dat and connect to them consecutively.
Corresponding ".time" files are also used in that case (if they exist).
@# -----------------------------------------------------------------------------
@article Http
@messageconnector-summary
@# -----------------------------------------------------------------------------
@article ServerSocket
@messageconnector-summary
@# -----------------------------------------------------------------------------
@article ClientSocket
@messageconnector-summary
@# -----------------------------------------------------------------------------
@article NioServer
@messageconnector-summary
@# -----------------------------------------------------------------------------
@article OnDemand
@messageconnector-summary
@# -----------------------------------------------------------------------------
@article Address
To create a connection using any QDS tool one must specify an address.
Depending on an address format different message connectors are used to establish
connection.

To establish multiple simultaneous connections multiple addresses can be specified in one of two ways:
	(<address1>)(<address2>)...(<addressN>)
	<address1>/<address2>/.../<addressN>

The first way is preferred. The second way is legacy and is not recommended.

Every single address has the following format:
	[<filter>@]<address-itself>[<connector-properties>].

<filer> is used to configure data or subscription filter in message adapter factory
(see @link{filters}).

<connector-properties> is the list of initial properties passed to a
connector. They have a form of comma-separated list of pairs <key>=<value>
enclosed in square [...] or round (...) brackets. Multiple pairs of brackets
are also allowed, so [key1=val1,key2=val2] has the same meaning as
[key1=val1][key2=val2].

<address-itself> format depends on particular connector.

Available connectors are:
@list-connectors
To get detailed information about address format and available properties of some
message connector use "Help <connector name>".
@# ====== VARIOUS ARTICLES =====================================================
@article Scheme

The "Scheme" essence defines overall scheme of used data records and their
fields. It contains an indexed list of data records and provides quick access
to them. It also provides information about implementation of services, that
are used in specific system (SubscriptionFilterFactory, HistorySubscriptionFilter,
QDErrorHandler). Scheme is represented by some class that implements
com.devexperts.qd.DataScheme interface.

To define specific scheme one can use JVM option "scheme" ("java -Dscheme=<scheme> ...").
Most of QDS tools take <scheme> as their first parameter (if it was not already
defined as JVM option only). Here <scheme> has a form of [[<jar-file>]!][<scheme-class>]
or just <jar-file> (must end with '.jar' then). <jar-file>! is optional if
<scheme-class> is in classpath. <scheme-class> is optional if <jar-file>
defines default scheme. If default scheme is in classpath then just '!'
can be used.
@# -----------------------------------------------------------------------------
@article Filters

Filters are used to define subscription. They are specified in a special format.

Filters can be either simple or composite. Simple filters in their turn
divide into pattern filters, built-in filters and project-specific filters.

Pattern filters use simple glob-like format to specify matching symbols.
The easiest way to define one symbol filter is just to use it's name, like
"MSFT" (here and further quotes for clarity). If the pattern ends with * then
it will match all the symbols with specified prefix (for examlpe "NA*" will
accept all symbols that start with NA, and ".*" will accept all option symbols).
Whildcard (*) is only allowed in the end of a pattern.

Char classes are also allowed in pattern filters. They are grouped using
'[' and ']' and can be used in any part of a pattern. Several characters or
character intervals can be listed inside a char class. For example "[AC-FI-L]"
means one of A, C, D, E, F, I, J, K or L character. '^' as the first symbol inside a
char class means negation, i.e. "[^N-P]" means "all characters except N, O or
P". It can be used only once at the char class start.

Pattern filters can not contain some special symbols like punctuation marks,
quotes and brackets outside a char class. Lowercase latin letters are forbidden
at the beginning of a pattern (they are reserved for project-specific filters)
but they can be quoted using char classes.

Pattern filters can also be used to filter by record names. In order to do
it they must start with ':' (which means that the following pattern should be
applied to a record name, not to a symbol name). The format of a pattern in this
case is similar.

Project-specific filters have a form of lowercase words. They can be provided
by a class that implements SubscriptionFilterFactory service for specific project.
Following project-specific filters are available in this project:
@list-specific-filters

Any simple filters can be composed by boolean operations '&' (and), ',' (or)
and '!' (not). They can be grouped with '(' and ')'. For example, ".*&:Trade"
filter will accept all "Trade" records with symbol names starting with '.', i. e.
records about option trades. "(:Trade,:Quote,:Fundamental)&MSFT" filter will
accept one of three types of records about MSFT symbol.

Note, that all composite filter structures which consist only of simple record
filters are preprocessed effectively and they can be applied quickly not depending
on their complexity. Other simple filters (symbol or project-specific) can
not be composed effectively, so long symbol lists processing for example can slow
down performance.
@# -----------------------------------------------------------------------------
@article Time format

Many QDS tools handle dates, times and periods as values of their arguments,
options or some input or output values. A common flexible format exists for
parsing and formatting date-times and time-periods and it is used almost
everywhere.

Dates and times can be parsed from one of the following forms:

	'-'<period>
@br;It is parsed as current system time - <period>. Description of acceptable
time-period format follows below.

	<value-in-milliseconds>
@br;This is a standart java representation of time as a single long number.
Value of msecs is measured from 1970-01-01. Here the value should be positive
and have at least 9 digits (otherwise it could not be distinguished from date
in format 'yyyyMMdd'). Each date since 1970-01-03 can be represented in this
form.

	<date>[('T'|'t'|'-'|' ')<time>][<timezone>]
@br;This is the most formal way to represent a date-time. If time is missing
it is supposed to be '00:00:00'.

	['T'|'t']<time>[<timezone>]
@br;In this case current date is used.

Here <date> is one of:
	yyyy-MM-dd
	yyyyMMdd
@br;<time> is one of:
	HH:mm:ss
	HHmmss
	HH:mm
	HHmm
	HH
@br;<timezone> is a timezone in RFC 822 format: <sign>hhmm (shift relatively to GMT
timezone). Some standart abbreviations, such as GMT, UTC, MSK, EDT etc. are also
acceptable.

Examples of valid date-times:
	2007-11-02-12:34:56
	20070101-123456
	2007-11-02-123456
	t12:34:56
	2005-12-31 21:00:00
	2007-11-02
	2007-12-12t123456
	20071212-12:34
	2007-12-12T12MSK
	20000101 2200
	01:01
	12:12:12 +0300
	-P1234DT12H30M0S
	-123456   // -period
	12		  // hh
	1234      // hhmm
	123456    // hhmmss
	20010101  // yyyymmdd
	123456789 // long
	12+1200
	1234+1234 // 12:34:00 +1234

The general format for time periods is based on ISO8601 duration format:
"P<d>DT<h>H<m>M<s>S" (which means a period of <d> days, <h> hours, <m> minutes,
<s> seconds) Also little simplifications and modifications available:
	* Letters are case insensitive.
	* Letters 'P' and 'T' can be omitted.
	* Letter 'S' can be also omitted. In this case last number will be supposed
to be seconds.
	* Number of seconds can be fractional. So it is possible to define duration
accurate within milliseconds.
	* Every part can be omitted. In this case it is supposed that it's value is
zero.

Examples of valid time-periods:
	P1234DT12H30M0S
    p1
    t239
    PT0S
   	1.5
    436243.2346
    1m
    1h2s
    p1dt
@# -----------------------------------------------------------------------------
@article Text format

QDS tools that read or write data to/from console use uniform text format.
This format can also be used when taping/reading data into/from file (see
@link{Tape}, @link{FileConnector}).

All data in text format is split into blocks depending on its type.
Block type is described by a header. It can be one of:
	==QD_TICKER_DATA
	==QD_STREAM_DATA
	==QD_HISTORY_DATA
	==QD_RAW_DATA
	==QD_TICKER_ADD_SUBSCRIPTION
	==QD_TICKER_REMOVE_SUBSCRIPTION
	==QD_STREAM_ADD_SUBSCRIPTION
	==QD_STREAM_REMOVE_SUBSCRIPTION
	==QD_HISTORY_ADD_SUBSCRIPTION
	==QD_HISTORY_REMOVE_SUBSCRIPTION

All records inside a data block format are represented in following form:
	<record name> <symbol name> <field#1 value> ... <field#N value>
@br;Each token is separated by one or more spaces and/or tabs. Each record occupies
exactly one line. All field values are represented in text format. When reading
a record from text format some last field values can be omitted. In this case
they will automatically get values of 0 for int fields and null for obj fields.

Subscriptions inside a subscription block are represented as:
	<record name> <symbol name> [<subscription time>]
	<subscription time> should be represented corresponding to a time format
(see @link{Time format}).

Each time some record is met for the first time (either in data or subscription block)
it should be described. Record descriptions has following format:
	=<record name> Symbol <field#1 name> ... <field#N name>
@br;All field names are local (without "<record name>." prefix). Such descriptions are
used to attempt to set some correspondence between slightly different data schemes (see
@link{Scheme}).

Lines that start with # are skipped as line comments. Empty lines are also
allowed and skipped.

Encoding

In order to avoid problems with encoding and possibility of non-displayable
symbols appearing at the console data is encoded in a special way. All symbols
with ASCII codes out of range [32..126] are represented as \uXXXX, where XXXX
is their unicode code. Besides this some special symbol back-slash escaping
are used:
 	\t - tab character
 	\n - new line character
 	\r - carriage return character
 	\f - form-feed character
 	\\ - single back-slash '\'
 	\" - double quote '"'
 	\0 - symbol with 0 ASCII code
 	\NULL - null String
@br;If some token (record, field or symbol name or field value) contains
whitespaces or is an empty string then it is quoted with double quotes.

Examples of text format:

==QD_TICKER_DATA
@br;# This is a comment
@br;=Trade	Symbol	Last.Exchange	Last.Time	Last.Price	Last.Size	Last.Tick	Last.Change	Volume
@br;Trade	GOOG	D	20080325-172918+0300	452.47	100	1	-8.09	2,063,718
@br;Trade	IBM	N	20080325-172912+0300	117.60	100	2	-1.46	1,929,513
@br;=Quote	Symbol	Bid.Exchange	Bid.Price	Bid.Size	Ask.Exchange	Ask.Price	Ask.Size
@br;Quote	INTC	Q	22.09	777	Q	22.10	283
@br;Quote	MSFT	Q	29.03	27	Q	29.04	134
@br;Quote	/ES7ZG	\0	1476.75	0	\0	1477.50	0
@br;...

==QD_STREAM_ADD_SUBSCRIPTION
@br;=Message	Symbol	Message
@br;Message	categories.ALERT_MANAGEMENT
@br;=Underlying	Symbol	PutCallRatio	CallVolumeIndex	PutVolumeIndex	OptionVolumeIndex	ImpVolatility
@br;Underlying	/ER2
@br;=TradeHistory	Symbol	Time	Sequence	Exchange	Price	Size	Bid	Ask
@br;TradeHistory	$TIKI
@br;TradeHistory	/NQM8
@br;=Fundamental	Symbol	High.Price	Low.Price	Open.Price	Close.Price	OpenInterest
@br;Fundamental	MTK
@br;=Trade	Symbol	Last.Exchange	Last.Time	Last.Price	Last.Size	Last.Tick	Last.Change	Volume
@br;Trade	IBB
@br;TradeHistory	/YM
@br;...

NOTE: Lines in samples above are possibly separated to fit the screen. It is not
allowed to separate lines in arbitrary way in real text format.
@# ===== THE END ===============================================================